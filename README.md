# üéôÔ∏è Local AI Assistant with hardware Actions

This project is a **local voice assistant** for Raspberry Pi that can recognize speech, detect intents, and control hardware devices (Light, Fan, Servo) through GPIO.  
It supports both **real Raspberry Pi GPIO** mode and **simulation mode** for testing without hardware.

---

## System Architecture

![System Architecture](https://github.com/saifibolte/Local-AI-Assistant-with-Hardware-Actions/blob/adade25ce4ae1279b9fc54004dd00698f3e8d29a/figures/System%20Architecture.drawio.png)

### Flow:
1. **User speaks** ‚Üí Microphone captures audio.
2. **Vosk STT** converts audio ‚Üí text.
3. **Intent Detector**:
   - Routes small-talk ‚Üí GPT2 restricted + TTS.
   - Routes device commands ‚Üí GPIO Interface.
4. **GPIO Handler Layer**:
   - `--mode sim` ‚Üí Simulated GPIO.
   - `--mode rpi` ‚Üí Real Raspberry Pi GPIO.
5. **Output**:
   - Voice reply via **Silero TTS**.
   - Device control (Light, Fan, Servo).

---

## Project Structure
```
.
‚îú‚îÄ‚îÄ asr.py              # Speech-to-text (Vosk)
‚îú‚îÄ‚îÄ assistant.py        # Main assistant logic
‚îú‚îÄ‚îÄ gpio_rpi.py         # Real Raspberry Pi GPIO handler
‚îú‚îÄ‚îÄ gpio_sim.py         # Simulated GPIO handler
‚îú‚îÄ‚îÄ intents.py          # Intent detection (commands + small-talk)
‚îú‚îÄ‚îÄ tts.py              # Text-to-speech (Silero)
‚îú‚îÄ‚îÄ main.py             # Entry point
‚îú‚îÄ‚îÄ System Architecture.drawio.png
‚îî‚îÄ‚îÄ requirements.txt    # Dependencies
```

---

## Installation

### 1. Clone repo & install dependencies
```bash
git clone https://github.com/your-repo/pi-voice-assistant.git
cd pi-voice-assistant
pip install -r requirements.txt
```

### 2. Download Vosk Model
```bash
mkdir models
wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
unzip vosk-model-small-en-us-0.15.zip -d models/
```

---

## Usage

### Simulation Mode (no hardware required)
```bash
python main.py --model-path models/vosk-model-small-en-us-0.15 --mode sim
```

### Raspberry Pi Mode (with GPIO)
```bash
python main.py --model-path models/vosk-model-small-en-us-0.15 --mode rpi
```

---

## Voice Commands

| Command Example        | Action                           |
|-------------------------|----------------------------------|
| "Turn on the light"    | Light ‚Üí ON                      |
| "Switch off fan"       | Fan ‚Üí OFF                       |
| "Make the servo wave"  | Servo ‚Üí WAVE                    |
| "Blink the light"      | Light ‚Üí BLINK (3 times)         |
| "Hello / Hi"           | Small talk response             |

---

## Hardware Setup (Raspberry Pi)

- **GPIO Pin Map**:
  - `LIGHT` ‚Üí GPIO 17
  - `FAN` ‚Üí GPIO 27 (via L293D motor driver for DC motor)
  - `SERVO` ‚Üí GPIO 18 (PWM)

---

## Dependencies
- [Vosk](https://alphacephei.com/vosk/) (speech recognition)
- [Silero TTS](https://github.com/snakers4/silero-models) (text-to-speech)
- [SoundDevice](https://python-sounddevice.readthedocs.io/)
- [RPi.GPIO](https://pypi.org/project/RPi.GPIO/) (only on Raspberry Pi)
- PyTorch

Install via:
```bash
pip install vosk sounddevice torch RPi.GPIO
```

---

## üì∏ Demo

- User: *"Turn on the fan"*  
- Assistant: *"Okay, fan set to ON."*  
- Fan (DC motor) spins up via **L293D motor driver**.  
